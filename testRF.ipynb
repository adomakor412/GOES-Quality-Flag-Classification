{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'data/fitted_models/rf_model_down_upsample_2_set_depth_10.sav'\n",
    "FILE_NAME = 'test_files.txt'\n",
    "FILE_ROOT_PATH = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "files = []\n",
    "with open(FILE_NAME, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip('\\n')\n",
    "        files.append(FILE_ROOT_PATH + line)\n",
    "    \n",
    "n = 401401\n",
    "test_data = np.empty((n*len(files),4), float)\n",
    "test_label = np.empty((n*len(files)), int)\n",
    "\n",
    "counter = 0\n",
    "for file in files:\n",
    "    with h5py.File(file, 'r') as f:\n",
    "        index = f['label'][()]\n",
    "        data = f['data'][()]\n",
    "        test_data[counter*n:(counter+1)*n] = data\n",
    "        test_label[counter*n:(counter+1)*n] = index\n",
    "        \n",
    "    counter += 1\n",
    "    print(str(int((counter/len(files))*100)) + '%', end='\\r', flush = True)\n",
    "    \n",
    "test_label[np.where(test_label > 4)] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   3 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed:   29.3s\n",
      "[Parallel(n_jobs=5)]: Done  15 tasks      | elapsed:   45.9s\n",
      "[Parallel(n_jobs=5)]: Done  22 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=5)]: Done  51 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=5)]: Done  62 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=5)]: Done  75 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=5)]: Done  88 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=5)]: Done 100 out of 100 | elapsed:  4.2min finished\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   3 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=5)]: Done  15 tasks      | elapsed:   45.9s\n",
      "[Parallel(n_jobs=5)]: Done  22 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=5)]: Done  51 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=5)]: Done  62 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=5)]: Done  75 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=5)]: Done  88 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=5)]: Done 100 out of 100 | elapsed:  4.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Acc:  0.9700282020288455\n",
      "Average Recall:  0.9700282020288455\n",
      "Single Class Recall:  [9.99861655e-01 1.38855531e-02 2.22373949e-03 7.33146641e-04\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(MODEL_PATH, 'rb'))\n",
    "\n",
    "acc = loaded_model.score(test_data, test_label)\n",
    "predict_label = loaded_model.predict(test_data)\n",
    "overall_recall = recall_score(test_label, predict_label, average='weighted') #note try to run predict only once \n",
    "class_recall = recall_score(test_label, predict_label, average=None)\n",
    "bal_acc = balanced_accuracy_score(test_label, predict_label)\n",
    "\n",
    "print('Mean Acc: ', acc)\n",
    "print('Average Recall: ', overall_recall)\n",
    "print('Single Class Recall: ', class_recall)\n",
    "print('Balanced Acc: ', bal_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
